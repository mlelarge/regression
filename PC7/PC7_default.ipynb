{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f095fb",
   "metadata": {},
   "source": [
    "# PC7 -  Logistic Regression case study: Default\n",
    "\n",
    "cours [MAP 535](https://moodle.polytechnique.fr/course/view.php?id=14763): Regression de Karim Lounici\n",
    "\n",
    "auteur de ce notebook python : Marc Lelarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be91534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette='colorblind',style='darkgrid')\n",
    "\n",
    "#import sys\n",
    "#sys.path.append('../')\n",
    "from model_selection_python import backwardSelection, forwardSelection, bothSelection, anova_glm, anova_onemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df1974",
   "metadata": {},
   "source": [
    "## 1  Logistic Regression\n",
    "\n",
    "We are interested in predicting whether an individual will default on his or her credit card payment, on the basis of annual income and monthly credit card balance (levels of debt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7da65",
   "metadata": {},
   "source": [
    "### 1.1 Import this data set and look at/play with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Default\",'ISLR').data\n",
    "\n",
    "df = pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d63393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b3e3c",
   "metadata": {},
   "source": [
    "### 1.2 Before implementing a logistic regression, look at the following estimate. Comment its performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier = lambda x: 'No' if (np.mean(df['default_Yes']==1)<0.5) else 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455e278",
   "metadata": {},
   "source": [
    "This classifier outputs the most frequent value (“No” in this case) for every new observations. In other words, this classifier always predict the absence of payment default. This is a dumb estimate since it does not use the variable in the data set (except “default”) to predict. It is however important to obtain a baseline for the error. Here, we would like our logistic regression to have an error lower than the error of the previous estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc3f3d",
   "metadata": {},
   "source": [
    "### 1.3 First visualize the relation between each variable and the default payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d337a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bfbc6e5",
   "metadata": {},
   "source": [
    "### 1.4 We are now implementing a logistic regression using the function “GLM”. \n",
    "\n",
    "Indeed, logistic regression is a particular class of generalized linear model (glm). At first, we will try to explain the probability of default with the balance variable. Implement a logistic regression with this variable.\n",
    "\n",
    "Hint: use [sm.families.Binomial](https://www.statsmodels.org/dev/generated/statsmodels.genmod.families.family.Binomial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70eb04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1e3e621",
   "metadata": {},
   "source": [
    "Use the `anova_glm` fucntion to compare nested models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaa6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d480ee7f",
   "metadata": {},
   "source": [
    "Retrieve the values given (value of the test statistic, the residual deviance of both models 2920.7 and 1596.5, p.value, df 1) and take a decision to keep one model. Hint: the log-likelihood of a model is given with the [loglike](https://www.statsmodels.org/dev/dev/generated/statsmodels.base.model.LikelihoodModel.loglike.html#statsmodels.base.model.LikelihoodModel.loglike) function applied on an object glm with parameters fitted glm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc57660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d67b6a2",
   "metadata": {},
   "source": [
    "### 1.5 Write mathematically the logistic model you just implemented. \n",
    "\n",
    "Once the coefficient have been estimated, how do you predict the default for a new data point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b95583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2b7a188",
   "metadata": {},
   "source": [
    "### 1.6  Using logistic regression, predict the default for a person whose balance is equal to 1600.\n",
    "\n",
    "The estimated probability of default can be computed using the equation above (where the true coefficients are replaced by their estimated values). To obtain a prediction, we just need to know if the predicted value is lower than 0.5. If it is lower, then the algorithm predicts 1 else 0.\n",
    "\n",
    "To obtain the values predicted by the model model, we first bring together the new data in an array with the same structure as the initial data table (keep the order of variables, including constant):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b51242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a840c2",
   "metadata": {},
   "source": [
    "### 1.7  Compute the confusion matrix associated to the logistic regression predictions.\n",
    "\n",
    "That is the matrix where you compare the observed values for “default” and the predicted ones. You can use the function [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) from sklearn.metrics\n",
    "\n",
    "What is the classifier error? What are the true positive and false positive rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0d723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd2b820",
   "metadata": {},
   "source": [
    "The error rate obtained in this way is generally optimistic as the same sample is used to construct the model and to estimate the misclassification rate. We can obtain a more precise estimation using cross-validation methods. In order to do so, we use the function cv.glm. First of all, the package boot must be loaded and a cost function created which admits the observed values of Y as well as the predicted probabilities as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a14433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0fcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e41f1600",
   "metadata": {},
   "source": [
    "### 1.8 We can change the threshold $0.5$ in the logistic regression procedure.\n",
    "\n",
    "The estimated coefficients are unchanged, so is the estimated probability, but now we will predict 1 if $\\hat{p} (x)\\gt0.2$. Compute the confusion matrix and the error. What are the true positive and false positive rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19864fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdaa0b55",
   "metadata": {},
   "source": [
    "### 1.9  ROC\n",
    "\n",
    "The ROC (Receiver Operating Characteristic) is a curve generated by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. Using the functions “prediction” and “performance” plot the ROC curve. Plot on this curve the two points corresponding to the previous thereshold 0.5 and 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e095a0",
   "metadata": {},
   "source": [
    "### 1.10  AUC\n",
    "\n",
    "The AUC (area under the curve, which are typical performance measurements for a binary classifier) is the area under the ROC curve. As a rule of thumb, a model with good predictive ability should have an AUC closer to 1 (1 is ideal) than to 0.5. Use the function roc_auc_score from sklearn to compute the auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f481c7",
   "metadata": {},
   "source": [
    "## 2  Logistic regression with multiple explanatory variables\n",
    "\n",
    "First of all, we randomly separate the database into:\n",
    "- a 8000 size learning sample that will be used to estimate the (or the logistics model(s);\n",
    "- a 2000 test sample size that will be used to measure performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6782ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "perm = np.random.choice(len(df),size=8000,replace=False)\n",
    "app = df.loc[perm]\n",
    "test = df.loc[~df.index.isin(perm),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fb63c",
   "metadata": {},
   "source": [
    "### 2.1  Implement a logistic regression using all variables in the data set on the training set. \n",
    "\n",
    "Comment the python output. How do you interpret each coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e57cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06aec72e",
   "metadata": {},
   "source": [
    "### 2.2 Compute the confusion matrix of the model and its error. \n",
    "\n",
    "Plot the ROC curve and compute the AUC. Comment on these results.\n",
    "\n",
    "Predictions on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba784cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression",
   "language": "python",
   "name": "regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
